{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83b2119",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# 下载modelscope模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1707de7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T03:22:11.377536Z",
     "start_time": "2023-12-05T03:22:11.366583Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from modelscope import Model, AutoTokenizer\n",
    "\n",
    "\n",
    "# model = Model.from_pretrained(\"modelscope/Llama-2-7b-ms\", revision='v1.0.1', device_map='auto', torch_dtype=torch.float16)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"modelscope/Llama-2-7b-ms\", revision='v1.0.1')\n",
    "\n",
    "# prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate\n",
    "# generate_ids = model.generate(inputs.input_ids.to(model.device), max_length=30)\n",
    "# print(tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "432326a9",
   "metadata": {},
   "source": [
    "# 导包与传入参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7902c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:36.567980Z",
     "start_time": "2023-12-05T07:32:28.170797Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\bitsandbytes\\cuda_setup\\main.py:112: UserWarning: Loading CUDA version: BNB_CUDA_VERSION=18\n",
      "================================================================================\n",
      "\n",
      "\n",
      "  warn((f'\\n\\n{\"=\"*80}\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin C:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import LlamaForCausalLM, LlamaTokenizer, Trainer, DataCollatorForSeq2Seq\n",
    "login_token = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3371374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:42.059905Z",
     "start_time": "2023-12-05T07:32:42.047937Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "import peft\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24b9f2b",
   "metadata": {},
   "source": [
    "**TODO:内置参数**（不知道是啥）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5013bfd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:42.914007Z",
     "start_time": "2023-12-05T07:32:42.899065Z"
    }
   },
   "outputs": [],
   "source": [
    "device_map = \"auto\"\n",
    "# world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "# if world_size != 1:\n",
    "#     device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "#     gradient_accumulation_steps = gradient_accumulation_steps // world_size\n",
    "\n",
    "# # Check if parameter passed or if set within environ\n",
    "# use_wandb = len(wandb_project) > 0 or (\n",
    "#     \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n",
    "# )\n",
    "# # Only overwrite environ if wandb param passed\n",
    "# if len(wandb_project) > 0:\n",
    "#     os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "# if len(wandb_watch) > 0:\n",
    "#     os.environ[\"WANDB_WATCH\"] = wandb_watch\n",
    "# if len(wandb_log_model) > 0:\n",
    "#     os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706cf2cd",
   "metadata": {},
   "source": [
    "# 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f5d4753",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:44.939036Z",
     "start_time": "2023-12-05T07:32:43.585456Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-265d39595e7fd67a\n",
      "Found cached dataset json (F:/huggingface/datasets/json/default-265d39595e7fd67a/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
      "100%|█████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 125.34it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "data_path = './train_v3.json'\n",
    "\n",
    "if data_path.endswith(\".json\") or data_path.endswith(\".jsonl\"):\n",
    "    data = load_dataset(\"json\", data_files=data_path)\n",
    "else:\n",
    "    data = load_dataset(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad30154",
   "metadata": {},
   "source": [
    "**查看原始数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83ff4911",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:51.568233Z",
     "start_time": "2023-12-05T07:32:51.554271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'input', 'output'],\n",
       "        num_rows: 55\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93173bb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:51.988483Z",
     "start_time": "2023-12-05T07:32:51.970240Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instruction': 'Please extract the entity of person in the input sentence given below , the entity of person refers to the entity that represents the identity or role of a specific person in the input sentense .', 'input': 'At the moment Shalev is in Levico Terme , Trento , Italy for a conference .', 'output': '<im_start> I can extract entities for you, the extracted entities are <<< Shalev >>>  <im_end>'}\n",
      "{'instruction': 'Please extract the entity of person in the input sentence given below , the entity of person refers to the entity that represents the identity or role of a specific person in the input sentense .', 'input': 'If you already own a Beavertail cactus , you can make your own cuttings .', 'output': '<im_start> I can extract entities for you, the extracted entities are <<< you >>>  <im_end>'}\n",
      "{'instruction': 'Please extract the entity of person in the input sentence given below , the entity of person refers to the entity that represents the identity or role of a specific person in the input sentense .', 'input': 'And for me , what I want the purpose to be , is to inspire people .', 'output': '<im_start> I can extract entities for you, the extracted entities are <<< me >>> <<< I >>> <<< people >>>  <im_end>'}\n",
      "{'instruction': 'Please extract the entity of place in the input sentence given below , the entity of place refers to the entity that represents a specific location, position, or area in the input sentence .', 'input': 'From the Southwest / Oklahoma City - I-44 East , aka the \" Turner Turnpike . \"', 'output': '<im_start> I can extract entities for you, the extracted entities are <<< the Southwest >>> <<< Oklahoma City >>>  <im_end>'}\n",
      "{'instruction': 'Please extract the entity of substance in the input sentence given below , the entity of substance refers to the entity that represents a specific substance or class of substances in the input sentence .', 'input': 'The cupcakes will not be as light and fluffy , however , so be prepared for a heavier cupcake if you add fruit but the added moisture content is a definite plus .', 'output': '<im_start> I can extract entities for you, the extracted entities are <<< fruit >>> <<< added moisture content >>>  <im_end>'}\n"
     ]
    }
   ],
   "source": [
    "for index, item in enumerate(data['train']):\n",
    "    if index < 5:\n",
    "        print(item)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ffb12b",
   "metadata": {},
   "source": [
    "# 预训练模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecd0e68a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:52.720446Z",
     "start_time": "2023-12-05T07:32:52.707483Z"
    }
   },
   "outputs": [],
   "source": [
    "# 传入参数\n",
    "base_model = 'meta-llama/Llama-2-7b-hf'\n",
    "# base_model = r'C:\\Users\\joyho\\.cache\\modelscope\\hub\\modelscope\\Llama-2-7b-ms'\n",
    "output_dir = 'lora-alpaca_origin'\n",
    "batch_size = 128\n",
    "micro_batch_size = 4\n",
    "lora_r = 32 # lora的维度 矩阵分解\n",
    "lora_alpha = 16 # lora的权重\n",
    "lora_dropout = 0.05\n",
    "lora_target_modules = [\n",
    "    \"q_proj\",\n",
    "    \"v_proj\",\n",
    "] # 指定在哪些线形层做lora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d224284a",
   "metadata": {},
   "source": [
    "## LLM加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f652bf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:57.370732Z",
     "start_time": "2023-12-05T07:32:53.319729Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|███████████████████████████████████████████| 2/2 [00:02<00:00,  1.19s/it]\n",
      "C:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the cpu.\n"
     ]
    }
   ],
   "source": [
    "# 加载base model\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    load_in_8bit=False,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    "    token=login_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8ad7366",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:59.188938Z",
     "start_time": "2023-12-05T07:32:59.099596Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\peft\\utils\\other.py:136: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Opts: 量化训练，减小显存使用，训练效果下降\n",
    "model = prepare_model_for_int8_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698f0454",
   "metadata": {},
   "source": [
    "**查看模型结构**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aebed7ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:32:59.583216Z",
     "start_time": "2023-12-05T07:32:59.564263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.modules of LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142abf0a",
   "metadata": {},
   "source": [
    "## LoRA训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd9ddb32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:02.856848Z",
     "start_time": "2023-12-05T07:33:02.163908Z"
    }
   },
   "outputs": [],
   "source": [
    "config = LoraConfig(\n",
    "    r=lora_r,\n",
    "    lora_alpha=lora_alpha,\n",
    "    target_modules=lora_target_modules,\n",
    "    lora_dropout=lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "model = get_peft_model(model, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c041195b",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0caec6d",
   "metadata": {},
   "source": [
    "## 预训练分词器加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d11f8c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:08.360204Z",
     "start_time": "2023-12-05T07:33:07.364202Z"
    }
   },
   "outputs": [],
   "source": [
    "# 加载分词器\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10b8e84",
   "metadata": {},
   "source": [
    "**配置分词器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fec0ab4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:09.013621Z",
     "start_time": "2023-12-05T07:33:08.999658Z"
    }
   },
   "outputs": [],
   "source": [
    "# 设置pad token为unk\n",
    "tokenizer.pad_token_id = 0\n",
    "# 设置在字符串左边填充\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a64a1",
   "metadata": {},
   "source": [
    "pad token: 一种特殊的令牌，用于使令牌阵列具有相同的大小以进行批处理。然后将被注意力机制或损失计算忽略。\n",
    "\n",
    "* \\<UNK\\>: 低频词或未在词表中的词\n",
    "* \\<PAD\\>: 补全字符\n",
    "* \\<GO\\>/\\<SOS\\>: 句子起始标识符\n",
    "* \\<EOS\\>: 句子结束标识符\n",
    "* \\[SEP\\]：两个句子之间的分隔符\n",
    "* \\[MASK\\]：填充被掩盖掉的字符\n",
    "\n",
    "Bert标识符\n",
    "* \\[CLS\\]：句子开头，以\\[CLS\\]开头，随后跟句子的第一个单词\n",
    "\n",
    "**调用分词器进行分词**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1261a75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:09.802879Z",
     "start_time": "2023-12-05T07:33:09.788470Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def tokenize(prompt, add_eos_token=True):\n",
    "    '''对输入str进行分词\n",
    "    \n",
    "    :param prompt 根据模板构造好的提示词（字符串）\n",
    "    :param add_eos_token 如果分词结果最后一位不是<句子起始标识符>，手动添加。\n",
    "    \n",
    "    输出：字典dict_keys(['input_ids', 'attention_mask','labels'])，其中labels就是input_ids。\n",
    "    '''\n",
    "    result = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=cutoff_len,\n",
    "        padding=False,\n",
    "        return_tensors=None,\n",
    "    ) # dict_keys(['input_ids', 'attention_mask'])\n",
    "    \n",
    "    # 如果分词结果最后一位不是<句子起始标识符> and 未被cutoff and 需要添加eos，手动添加\n",
    "    # TODO: 被cutoff的句子最后一位就不是<EOS>，不处理吗？\n",
    "    if (\n",
    "        result[\"input_ids\"][-1] != tokenizer.eos_token_id\n",
    "        and len(result[\"input_ids\"]) < cutoff_len\n",
    "        and add_eos_token\n",
    "    ):\n",
    "        result[\"input_ids\"].append(tokenizer.eos_token_id)\n",
    "        result[\"attention_mask\"].append(1)\n",
    "    # 额外添加label key，应该是跟训练有关系\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2eb94f",
   "metadata": {},
   "source": [
    "## prompt构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1c1581e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:10.700163Z",
     "start_time": "2023-12-05T07:33:10.683194Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.prompter import Prompter\n",
    "prompt_template_name = \"alpaca\" # TODO: 这模板也不知道是啥文件\n",
    "cutoff_len = 1024 # 超出长度的prompt会被切断。TODO: 这个没用啊\n",
    "prompter = Prompter(prompt_template_name)\n",
    "train_on_inputs = True # 是否不计算输入的损失\n",
    "add_eos_token = False # 是否添加句子结束标识符"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792ac0e",
   "metadata": {},
   "source": [
    "**查看构造&分词结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a444ff85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:27.177276Z",
     "start_time": "2023-12-05T07:33:27.160274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "length of seq: 139\n",
      "====================================================================================================\n",
      "Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Please extract the entity of person in the input sentence given below , the entity of person refers to the entity that represents the identity or role of a specific person in the input sentense .\n",
      "\n",
      "### Input:\n",
      "At the moment Shalev is in Levico Terme , Trento , Italy for a conference .\n",
      "\n",
      "### Response:\n",
      "<im_start> I can extract entities for you, the extracted entities are <<< Shalev >>>  <im_end>\n",
      "====================================================================================================\n",
      "{'input_ids': [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 12148, 6597, 278, 7855, 310, 2022, 297, 278, 1881, 10541, 2183, 2400, 1919, 278, 7855, 310, 2022, 14637, 304, 278, 7855, 393, 11524, 278, 10110, 470, 6297, 310, 263, 2702, 2022, 297, 278, 1881, 2665, 1947, 869, 13, 13, 2277, 29937, 10567, 29901, 13, 4178, 278, 3256, 1383, 744, 29894, 338, 297, 20708, 1417, 323, 10877, 1919, 1605, 9239, 1919, 12730, 363, 263, 21362, 869, 13, 13, 2277, 29937, 13291, 29901, 13, 29966, 326, 29918, 2962, 29958, 306, 508, 6597, 16212, 363, 366, 29892, 278, 23892, 16212, 526, 3532, 29966, 1383, 744, 29894, 8653, 29871, 529, 326, 29918, 355, 29958], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "data_index = 0\n",
    "full_prompt = prompter.generate_prompt(\n",
    "                data['train'][data_index][\"instruction\"],\n",
    "                data['train'][data_index][\"input\"],\n",
    "                data['train'][data_index][\"output\"],\n",
    "            )\n",
    "tokenized_full_prompt = tokenizer(\n",
    "                        full_prompt,\n",
    "                        truncation=True,\n",
    "                        max_length=cutoff_len,\n",
    "                        padding=False,\n",
    "                        return_tensors=None,\n",
    "                        )\n",
    "print('='*100)\n",
    "print(f\"length of seq: {len(tokenized_full_prompt['input_ids'])}\")\n",
    "print('='*100)\n",
    "print(full_prompt) # 查看构造后的结果\n",
    "print('='*100)\n",
    "print(tokenized_full_prompt) # 查看分词后的结果\n",
    "print('='*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31fee708",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:28.403638Z",
     "start_time": "2023-12-05T07:33:28.387166Z"
    },
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "def generate_and_tokenize_prompt(data_point):\n",
    "    # 根据所有features和labels进行full_prompt构造，并作分词\n",
    "    full_prompt = prompter.generate_prompt(\n",
    "        data_point[\"instruction\"],\n",
    "        data_point[\"input\"],\n",
    "        data_point[\"output\"],)\n",
    "    tokenized_full_prompt = tokenize(full_prompt)\n",
    "    \n",
    "    # 如果mask input loss\n",
    "    if not train_on_inputs:\n",
    "        user_prompt = prompter.generate_prompt(\n",
    "            data_point[\"instruction\"], data_point[\"input\"]\n",
    "        )\n",
    "        tokenized_user_prompt = tokenize(\n",
    "            user_prompt, add_eos_token=add_eos_token\n",
    "        )\n",
    "        user_prompt_len = len(tokenized_user_prompt[\"input_ids\"])\n",
    "\n",
    "        if add_eos_token:\n",
    "            user_prompt_len -= 1\n",
    "\n",
    "        tokenized_full_prompt[\"labels\"] = [\n",
    "            -100\n",
    "        ] * user_prompt_len + tokenized_full_prompt[\"labels\"][\n",
    "            user_prompt_len:\n",
    "        ]  # could be sped up, probably\n",
    "    # TODO: 额外设置了俩key，不知道有啥用\n",
    "    tokenized_full_prompt[\"pos\"] = [1111,1111]\n",
    "    tokenized_full_prompt[\"neg\"] = [0000,0000]\n",
    "\n",
    "    return tokenized_full_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f8191f",
   "metadata": {},
   "source": [
    "## 分割数据集&乱序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1c0b37f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:29.513894Z",
     "start_time": "2023-12-05T07:33:29.346201Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.arrow_dataset:Loading cached split indices for dataset at F:\\huggingface\\datasets\\json\\default-265d39595e7fd67a\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-f1ae9f9a2b83c151.arrow and F:\\huggingface\\datasets\\json\\default-265d39595e7fd67a\\0.0.0\\0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51\\cache-251802cba5d33541.arrow\n",
      "100%|██████████████████████████████████████████████████████████████████| 45/45 [00:00<00:00, 1002.68ex/s]\n",
      "100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 338.59ex/s]\n"
     ]
    }
   ],
   "source": [
    "val_set_size = 10\n",
    "if val_set_size > 0:\n",
    "    train_val = data[\"train\"].train_test_split(\n",
    "        test_size=val_set_size, shuffle=True, seed=42\n",
    "    )\n",
    "\n",
    "    train_data = (\n",
    "        train_val[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    )\n",
    "    val_data = (\n",
    "        train_val[\"test\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    )\n",
    "else:\n",
    "    train_data = data[\"train\"].shuffle().map(generate_and_tokenize_prompt)\n",
    "    val_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3a99420",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:36.094193Z",
     "start_time": "2023-12-05T07:33:36.082225Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb065e0",
   "metadata": {},
   "source": [
    "## Data Collector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3da20690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:37.016167Z",
     "start_time": "2023-12-05T07:33:36.999213Z"
    }
   },
   "outputs": [],
   "source": [
    "class CustomDataCollatorForSeq2Seq(DataCollatorForSeq2Seq):\n",
    "    def __call__(self, features, return_tensors=None):\n",
    "        feat = super().__call__(features, return_tensors=None)\n",
    "#        print(\"feat:\")\n",
    "#        print(feat)\n",
    "        input_ids_batch = feat[\"input_ids\"].tolist()\n",
    "        origin_arr = []\n",
    "        pos_arr = []\n",
    "        neg_arr = []\n",
    "        for input_ids in input_ids_batch:\n",
    "            input_str = \"_\".join([str(item) for item in input_ids])\n",
    "            origin_str = \"_\".join(origin)\n",
    "            prefix_str = \"_\".join(prefix)\n",
    "            suffix_str = \"_\".join(suffix)\n",
    "            sentence_str = \"_\".join(input)\n",
    "\n",
    "            origin_start = input_str.find(origin_str)\n",
    "\n",
    "            origin_index = input_str[0:origin_start + len(origin_str)].count(\"_\") + 1\n",
    "\n",
    "            origin_arr.append(origin_index)\n",
    "\n",
    "            prefix_start = input_str.find(prefix_str)\n",
    "            prefix_index = input_str[0:prefix_start + len(prefix_str)].count(\"_\") + 1\n",
    "\n",
    "            input_start = input_str.find(sentence_str)\n",
    "            input_index = input_str[0:input_start + len(sentence_str)].count(\"_\") + 1\n",
    "\n",
    "\n",
    "            suffix_start = input_str.find(suffix_str)\n",
    "            suffix_index = input_str[0:suffix_start].count(\"_\") - 1\n",
    "\n",
    "            entity_ids = input_ids[prefix_index: suffix_index + 1]\n",
    "            overlap_ids = longest_common_sublist(input_ids[input_index:prefix_index], entity_ids)\n",
    "\n",
    "            sentence_list = input_ids[input_index:prefix_index]\n",
    "            \n",
    "            pos_start = input_index + overlap_ids[0] - overlap_ids[2]\n",
    "            pos_end = input_index + overlap_ids[0] - overlap_ids[2] + len(entity_ids)\n",
    "            pos_arr.append([pos_start, pos_end - 1])\n",
    "            neg_arr.append([pos_start - 1, pos_start - 2, pos_end, pos_end + 1])\n",
    "            \n",
    "        feat[\"origin\"] = torch.tensor(origin_arr)\n",
    "        feat[\"pos\"] = torch.tensor(pos_arr)\n",
    "        feat[\"neg\"] = torch.tensor(neg_arr)\n",
    "\n",
    "        \n",
    "        return feat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a98cf",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21ba435",
   "metadata": {},
   "source": [
    "## 训练配置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b09fedb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:39.831336Z",
     "start_time": "2023-12-05T07:33:39.819877Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "micro_batch_size = 1\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "cutoff_len = 256\n",
    "resume_from_checkpoint = False\n",
    "\n",
    "# TODO: 下面都是啥玩意\n",
    "gradient_accumulation_steps = batch_size // micro_batch_size\n",
    "group_by_length = False\n",
    "world_size = int(os.environ.get(\"WORLD_SIZE\", 1))\n",
    "ddp = world_size != 1\n",
    "if ddp != 1:\n",
    "    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n",
    "    gradient_accumulation_steps = gradient_accumulation_steps // world_size\n",
    "\n",
    "# TODO: wandb是啥玩意\n",
    "wandb_project = ''\n",
    "wandb_run_name = \"\"\n",
    "wandb_watch = \"\"  # options: false | gradients | all\n",
    "wandb_log_model = \"\"\n",
    "# Check if parameter passed or if set within environ\n",
    "use_wandb = len(wandb_project) > 0 or (\n",
    "    \"WANDB_PROJECT\" in os.environ and len(os.environ[\"WANDB_PROJECT\"]) > 0\n",
    ")\n",
    "# Only overwrite environ if wandb param passed\n",
    "if len(wandb_project) > 0:\n",
    "    os.environ[\"WANDB_PROJECT\"] = wandb_project\n",
    "if len(wandb_watch) > 0:\n",
    "    os.environ[\"WANDB_WATCH\"] = wandb_watch\n",
    "if len(wandb_log_model) > 0:\n",
    "    os.environ[\"WANDB_LOG_MODEL\"] = wandb_log_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b118993",
   "metadata": {},
   "source": [
    "**如果断点续训**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "efe1ae65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:40.529146Z",
     "start_time": "2023-12-05T07:33:40.515293Z"
    }
   },
   "outputs": [],
   "source": [
    "if resume_from_checkpoint:\n",
    "    # Check the available weights and load them\n",
    "    checkpoint_name = os.path.join(\n",
    "        resume_from_checkpoint, \"pytorch_model.bin\"\n",
    "    )  # Full checkpoint\n",
    "    if not os.path.exists(checkpoint_name):\n",
    "        checkpoint_name = os.path.join(\n",
    "            resume_from_checkpoint, \"adapter_model.bin\"\n",
    "        )  # only LoRA model - LoRA config above has to fit\n",
    "        resume_from_checkpoint = (\n",
    "            False  # So the trainer won't try loading its state\n",
    "        )\n",
    "    # The two files above have a different name depending on how they were saved, but are actually the same.\n",
    "    if os.path.exists(checkpoint_name):\n",
    "        print(f\"Restarting from {checkpoint_name}\")\n",
    "        adapters_weights = torch.load(checkpoint_name)\n",
    "        set_peft_model_state_dict(model, adapters_weights)\n",
    "    else:\n",
    "        print(f\"Checkpoint {checkpoint_name} not found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ce420",
   "metadata": {},
   "source": [
    "**查看可训练参数个数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a7a0b42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:41.113862Z",
     "start_time": "2023-12-05T07:33:41.096223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16,777,216 || all params: 6,755,192,832 || trainable%: 0.24836028248556738\n"
     ]
    }
   ],
   "source": [
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f538d",
   "metadata": {},
   "source": [
    "## Train Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ffeba77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:41.706989Z",
     "start_time": "2023-12-05T07:33:41.691500Z"
    }
   },
   "outputs": [],
   "source": [
    "class ContrastiveTrainer(Trainer):\n",
    "    def contrastive_loss(self, hidden_states, origin, pos, neg):\n",
    "        # hidden_states:  B * L * D\n",
    "        # origin:  B\n",
    "        # pos : B * P\n",
    "        # neg : B * N\n",
    "        # B * 1 * D      pos_e:  B * P * D  neg_e: B * N * D\n",
    "        # P = 2  N = 4\n",
    "\n",
    "        origin_e = torch.gather(hidden_states, 1, origin.unsqueeze(-1).unsqueeze(-1).expand(-1,-1,hidden_states.shape[-1]))\n",
    "        pos_e = torch.gather(hidden_states, 1, pos.unsqueeze(-1).expand(-1,-1,hidden_states.shape[-1]))\n",
    "        neg_e = torch.gather(hidden_states, 1, neg.unsqueeze(-1).expand(-1,-1,hidden_states.shape[-1]))\n",
    "\n",
    "        origin_e = origin_e / origin_e.norm(dim=2, keepdim=True)\n",
    "        pos_e = pos_e / pos_e.norm(dim=2, keepdim=True)\n",
    "        neg_e = neg_e / neg_e.norm(dim=2, keepdim=True)\n",
    "\n",
    "\n",
    "        pos_score = (torch.mul(origin_e, pos_e).sum(dim=2)).sum(dim=1)\n",
    "        neg_score = (torch.mul(origin_e, neg_e).sum(dim=2)).sum(dim=1)\n",
    "\n",
    "        cl_loss = -torch.log(1e-10 + torch.sigmoid(pos_score - neg_score)).mean()\n",
    "\n",
    "        print(\"cl_loss:\", cl_loss)\n",
    "        return cl_loss\n",
    "\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "\n",
    "        origin = copy.deepcopy(inputs[\"origin\"])\n",
    "        pos = copy.deepcopy(inputs[\"pos\"])\n",
    "        neg = copy.deepcopy(inputs[\"neg\"])\n",
    "\n",
    "        if \"origin\" in inputs:\n",
    "            inputs.pop(\"origin\")\n",
    "        if \"pos\" in inputs:\n",
    "            inputs.pop(\"pos\")\n",
    "        if \"neg\" in inputs:\n",
    "            inputs.pop(\"neg\")\n",
    "        \n",
    "        if self.label_smoother is not None and \"labels\" in inputs:\n",
    "            labels = inputs.pop(\"labels\")\n",
    "        else:\n",
    "            labels = None\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "\n",
    "        cts_loss = self.contrastive_loss(outputs[\"hidden_states\"][26], origin, pos, neg)\n",
    "        # Save past state if it exists\n",
    "        # TODO: this needs to be fixed and made cleaner later.\n",
    "        if self.args.past_index >= 0:\n",
    "            self._past = outputs[self.args.past_index]\n",
    "\n",
    "        if labels is not None:\n",
    "            if is_peft_available() and isinstance(model, PeftModel):\n",
    "                model_name = unwrap_model(model.base_model)._get_name()\n",
    "            else:\n",
    "                model_name = unwrap_model(model)._get_name()\n",
    "            if model_name in MODEL_FOR_CAUSAL_LM_MAPPING_NAMES.values():\n",
    "                loss = self.label_smoother(outputs, labels, shift_labels=True)\n",
    "            else:\n",
    "                loss = self.label_smoother(outputs, labels)\n",
    "        else:\n",
    "            if isinstance(outputs, dict) and \"loss\" not in outputs:\n",
    "                raise ValueError(\n",
    "                    \"The model did not return a loss from the inputs, only the following keys: \"\n",
    "                    f\"{','.join(outputs.keys())}. For reference, the inputs it received are {','.join(inputs.keys())}.\"\n",
    "                )\n",
    "            # We don't use .loss here since the model may return tuples instead of ModelOutput.\n",
    "            loss = outputs[\"loss\"] if isinstance(outputs, dict) else outputs[0]\n",
    "        \n",
    "        loss += 0.001 * cts_loss\n",
    "#        print(0.0015)\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "393285df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:43.087088Z",
     "start_time": "2023-12-05T07:33:42.230427Z"
    }
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot copy out of meta tensor; no data!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mContrastiveTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtransformers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainingArguments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mper_device_train_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmicro_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_train_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43madamw_torch\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevaluation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_set_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mno\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msteps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_set_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_best_model_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mval_set_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mddp_find_unused_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mddp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup_by_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_by_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreport_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwandb_run_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muse_wandb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCustomDataCollatorForSeq2Seq\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\trainer.py:481\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[0;32m    480\u001b[0m ):\n\u001b[1;32m--> 481\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\transformers\\trainer.py:716\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[1;32m--> 716\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    717\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[1;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: Module._apply at line 810 (6 times)]\u001b[0m\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[1;32mC:\\Language\\Anaconda3\\envs\\llm\\lib\\site-packages\\torch\\nn\\modules\\module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Cannot copy out of meta tensor; no data!"
     ]
    }
   ],
   "source": [
    "trainer = ContrastiveTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=val_data,\n",
    "    args=transformers.TrainingArguments(\n",
    "        per_device_train_batch_size=micro_batch_size,\n",
    "        gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "        warmup_steps=100,\n",
    "        num_train_epochs=num_epochs,\n",
    "        learning_rate=learning_rate,\n",
    "        fp16=True,\n",
    "        logging_steps=10,\n",
    "        optim=\"adamw_torch\",\n",
    "        evaluation_strategy=\"steps\" if val_set_size > 0 else \"no\",\n",
    "        save_strategy=\"steps\",\n",
    "        eval_steps=200 if val_set_size > 0 else None,\n",
    "        save_steps=200,\n",
    "        output_dir=output_dir,\n",
    "        save_total_limit=3,\n",
    "        load_best_model_at_end=True if val_set_size > 0 else False,\n",
    "        ddp_find_unused_parameters=False if ddp else None,\n",
    "        group_by_length=group_by_length,\n",
    "        report_to=\"wandb\" if use_wandb else None,\n",
    "        run_name=wandb_run_name if use_wandb else None,\n",
    "    ),\n",
    "    data_collator=CustomDataCollatorForSeq2Seq(\n",
    "        tokenizer, pad_to_multiple_of=8, return_tensors=\"pt\", padding=True\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd90df5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T07:33:43.120000Z",
     "start_time": "2023-12-05T07:33:43.120000Z"
    }
   },
   "outputs": [],
   "source": [
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2021a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llm]",
   "language": "python",
   "name": "conda-env-llm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "291.25px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "225.17px",
    "left": "16.2159px",
    "right": "20px",
    "top": "517.932px",
    "width": "283.324px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
